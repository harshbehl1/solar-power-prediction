#Machine learning Model on Solar power in india
#Importing necessary Libraries 
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
df = pd.read_csv(r'C:\Users\Lenovo\Desktop\Harsash\solar power\Solar Power Plant Data.csv')
df.rename(columns={"Date-Hour(NMT)":"Date"}, inplace = True)
df["Date"] = pd.to_datetime(df["Date"], format='%d.%m.%Y-%H:%M')
df = df.set_index(["Date"])
df.head()
print(f'The data frame has {df.shape[0] } rows and {df.shape[1]} columns')
#information about dataset
df.info()
# Check for missing values in the dataset
missing_values = df.isnull().sum()
print("Missing values in each column:\n", missing_values)

# statistics
df.describe()

# Categorizing Sunshine Levels
def categorize_sunshine(value):
    if value == 0:
        return "Low"
    elif 0 < value <= 5:
        return "Medium"
    else:
        return "High"

df['SunshineLevel'] = df['Sunshine'].apply(categorize_sunshine)

# Count for each Sunshine Level category
sunshine_counts = df['SunshineLevel'].value_counts()

# Plotting Sunshine Levels Pie Chart
plt.figure(figsize=(8, 8))
plt.pie(sunshine_counts, labels=sunshine_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribution of Sunshine Levels')
plt.show()
# Categorizing System Production Levels
def categorize_production(value):
    if value == 0:
        return "Zero"
    elif 0 < value <= 10:
        return "Low"
    elif 10 < value <= 50:
        return "Moderate"
    else:
        return "High"

df['ProductionLevel'] = df['SystemProduction'].apply(categorize_production)

# Count for each System Production Level category
production_counts = df['ProductionLevel'].value_counts()

# Plotting System Production Levels Pie Chart
plt.figure(figsize=(8, 8))
plt.pie(production_counts, labels=production_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribution of System Production Levels')
plt.show()
# Group data by Sunshine Level and calculate mean System Production for each category
sunshine_production = df.groupby('SunshineLevel')['SystemProduction'].mean()

# Plot bar chart
plt.figure(figsize=(8, 6))
sunshine_production.plot(kind='bar', color='orange')
plt.title('Average System Production by Sunshine Level')
plt.xlabel('Sunshine Level')
plt.ylabel('Average System Production')
plt.show()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Sample data generation
np.random.seed(42)  # For reproducibility
data = {
    'WindSpeed': np.random.randint(5, 25, 100),  # WindSpeed between 5 and 25
    'Sunshine': np.random.randint(1, 12, 100),   # Sunshine hours between 1 and 12
    'AirPressure': np.random.randint(950, 1050, 100),  # AirPressure in hPa
    'Radiation': np.random.randint(100, 1000, 100),    # Radiation between 100 and 1000
    'AirTemperature': np.random.randint(15, 35, 100),  # Temperature between 15 and 35 degrees Celsius
    'SystemProduction': np.random.randint(200, 600, 100)  # Production between 200 and 600 units
}
df = pd.DataFrame(data)

# Set the figure size
plt.figure(figsize=(12, 6))

# Melt the DataFrame to long format for seaborn
df_melted = df.melt(var_name='Attribute', value_name='Value')

# Create a violin plot
sns.violinplot(x='Attribute', y='Value', data=df_melted)

# Set the title and labels
plt.title('Distribution of Weather Attributes and System Production')
plt.xlabel('Weather Attributes')
plt.ylabel('Value')

# Show the plot
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Sample data generation
np.random.seed(42)  # For reproducibility
data = {
    'WindSpeed': np.random.randint(5, 25, 100),  # WindSpeed between 5 and 25
    'Sunshine': np.random.randint(1, 12, 100),   # Sunshine hours between 1 and 12
    'AirPressure': np.random.randint(950, 1050, 100),  # AirPressure in hPa
    'Radiation': np.random.randint(100, 1000, 100),    # Radiation between 100 and 1000
    'AirTemperature': np.random.randint(15, 35, 100),  # Temperature between 15 and 35 degrees Celsius
    'SystemProduction': np.random.randint(200, 600, 100)  # Production between 200 and 600 units
}
df = pd.DataFrame(data)

# Calculate the mean values for selected attributes
attributes = ['WindSpeed', 'Sunshine', 'AirPressure', 'Radiation', 'AirTemperature', 'SystemProduction']
values = df[attributes].mean().values

# Prepare data for radar chart
num_vars = len(attributes)
angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
values = np.concatenate((values, [values[0]]))  # Closing the circle
angles += angles[:1]

# Plot radar chart
fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))
ax.fill(angles, values, color='blue', alpha=0.25)
ax.plot(angles, values, color='blue', linewidth=2)
ax.set_yticklabels([])

# Set the labels for each axis
ax.set_xticks(angles[:-1])
ax.set_xticklabels(attributes)

# Add a title
plt.title('Average Levels of Weather Attributes and System Production')
plt.show()


import pandas as pd
import matplotlib.pyplot as plt

# Selecting a subset of data and converting the date-hour column to datetime format
subset_data = df[['Date-Hour(NMT)', 'SystemProduction']].head(50)
subset_data['Date-Hour(NMT)'] = pd.to_datetime(subset_data['Date-Hour(NMT)'], format='%d.%m.%Y-%H:%M')

# Calculate the cumulative production changes using a rolling mean to smooth the data
subset_data['Change'] = subset_data['SystemProduction'].diff().fillna(0)
subset_data['Smoothed Change'] = subset_data['Change'].rolling(window=3, center=True).mean().fillna(subset_data['Change'])
subset_data['Cumulative'] = subset_data['Smoothed Change'].cumsum()

# Define colors: green for increase, red for decrease
colors = ['#3CB371' if val >= 0 else '#FF6347' for val in subset_data['Smoothed Change']]

# Create the waterfall chart
fig, ax = plt.subplots(figsize=(12, 6))
ax.bar(subset_data['Date-Hour(NMT)'].dt.strftime('%d-%m %H:%M'), subset_data['Smoothed Change'], color=colors,
       bottom=subset_data['Cumulative'] - subset_data['Smoothed Change'])
ax.set_title("Waterfall Chart for System Production", fontsize=16)
ax.set_xlabel("Date-Hour", fontsize=12)
ax.set_ylabel("Smoothed System Production Change", fontsize=12)

# Rotate x-axis labels and limit the number of labels displayed
ax.set_xticks(ax.get_xticks()[::5])  # Show every 5th timestamp to reduce clutter
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Define attributes without 'SystemProduction'
attributes = ['WindSpeed', 'Sunshine', 'AirPressure', 'Radiation', 'AirTemperature']

# Calculate the mean values for each attribute and the overall mean of system production
average_production = df['SystemProduction'].mean()
contributions = df[attributes].mean() - average_production

# Prepare data for waterfall plot
labels = contributions.index
values = contributions.values
running_total = np.insert(values.cumsum(), 0, 0)  # Start from zero for a clean waterfall

# Waterfall plot
plt.figure(figsize=(10, 6))
for i, (start, end) in enumerate(zip(running_total[:-1], running_total[1:])):
    plt.bar(i, end - start, bottom=start, color='green' if end > start else 'red')

# Formatting plot
plt.xticks(range(len(labels)), labels, rotation=45)
plt.ylabel('Contribution to Average Production')
plt.title('Waterfall Chart of Weather Factor Contributions to System Production')
plt.grid(axis='y')
plt.show()

import squarify

# Get mean values of attributes to visualize in a tree map
mean_values = df[attributes].mean()

# Tree map plot
plt.figure(figsize=(12, 8))
squarify.plot(sizes=mean_values, label=mean_values.index, alpha=0.7, color=plt.cm.Paired.colors)
plt.title("Treemap ")
plt.axis('off')
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Set the aesthetic style of the plots
sns.set_style("darkgrid")

# Select only numerical columns
numerical_data = df.select_dtypes(include=[np.number])

def remove_outliers_z_score(column, threshold=3):
    z_scores = np.abs(stats.zscore(column, nan_policy='omit'))
    return column[(z_scores < threshold)]

cleaned_data = numerical_data.apply(remove_outliers_z_score)

# Plot histograms for each numerical column
num_columns = cleaned_data.shape[1]
num_rows = (num_columns // 3) + (1 if num_columns % 3 != 0 else 0)  # Adjust row count

plt.figure(figsize=(15, num_rows * 4))  # Adjust the figure size based on the number of rows

for i, column in enumerate(cleaned_data.columns, 1):
    plt.subplot(num_rows, 3, i)

    # Apply log transformation for specific columns
    if column in ['Sunshine', 'SystemProduction']:
        # Ensure there are no negative values before log transformation
        data_to_plot = cleaned_data[column].dropna()
        data_to_plot = data_to_plot[data_to_plot > 0]  # Filter out non-positive values
        sns.histplot(np.log(data_to_plot), bins='auto', color='blue', stat='density', alpha=0.7)  # Log scale
        plt.title(f'Log Distribution of {column}', fontsize=14)
        plt.xlabel(f'Log({column})')
    else:
        sns.histplot(cleaned_data[column].dropna(), bins='auto', color='blue', stat='density', alpha=0.7)  # Normal histogram
        plt.title(f'Distribution of {column}', fontsize=14)
        plt.xlabel(column)
    
    plt.ylabel('Density')  # Change to density for clarity

plt.tight_layout()
plt.suptitle('Histograms of Numerical Variables', fontsize=16, y=1.02)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Set up the plot with specific size and layout
fig, ax = plt.subplots(3, 3, figsize=(20, 15), sharey=False)
fig.suptitle("Boxplots (Outliers Hidden)")

# SystemProduction
sns.boxplot(y=df["SystemProduction"], ax=ax[0, 0], showfliers=False)
ax[0, 0].set_xlabel("SystemProduction")

# WindSpeed
sns.boxplot(y=df["WindSpeed"], ax=ax[0, 1], showfliers=False)
ax[0, 1].set_xlabel("WindSpeed")

# Sunshine
sns.boxplot(y=df["Sunshine"], ax=ax[0, 2], showfliers=False)
ax[0, 2].set_xlabel("Sunshine")

# RelativeAirHumidity
sns.boxplot(y=df["RelativeAirHumidity"], ax=ax[1, 0], showfliers=False)
ax[1, 0].set_xlabel("RelativeAirHumidity")

# Radiation
sns.boxplot(y=df["Radiation"], ax=ax[1, 1], showfliers=False)
ax[1, 1].set_xlabel("Radiation")

# AirTemperature
sns.boxplot(y=df["AirTemperature"], ax=ax[1, 2], showfliers=False)
ax[1, 2].set_xlabel("AirTemperature")

# AirPressure
sns.boxplot(y=df["AirPressure"], ax=ax[2, 0], showfliers=False)
ax[2, 0].set_xlabel("AirPressure")

# Hide unused subplots
ax[2, 1].set_visible(False)
ax[2, 2].set_visible(False)

# Adjust layout for better spacing
plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Make room for the suptitle
plt.show()

# QQ Plots:
# Defining subplots:
from scipy import stats
import matplotlib.pyplot as plt
from statsmodels.graphics.gofplots import qqplot
fig, axe = plt.subplots(3, 3, sharey=False, figsize=(20, 20))
fig.suptitle("Quantile-Quantile Plots")
# Plotting SystemProduction data:
qqplot(df["SystemProduction"], ax=axe[0, 0], line="s");
axe[0, 0].set_title("SystemProduction")
# Plotting WindSpeed data:
qqplot(df["WindSpeed"], ax=axe[0, 1], line="s")
axe[0, 1].set_title("WindSpeed")
# Plotting Sunshine data:
qqplot(df["Sunshine"], ax=axe[0, 2], line="s")
axe[0, 2].set_title("Sunshine")
# Ploting RelativeAirHumidity:
qqplot(df["RelativeAirHumidity"], ax=axe[1, 0], line="s")
axe[1, 0].set_title("RelativeAirHumidity")
# Radiation:
qqplot(df["Radiation"], ax=axe[1, 1], line="s")
axe[1, 1].set_title("Radiation")
# AirTemperature:
qqplot(df["AirTemperature"], ax=axe[1, 2], line="s")
axe[1, 2].set_title("AirTemperature")
# AirPressure
qqplot(df["AirPressure"], ax=axe[2, 0], line="s")
axe[2, 0].set_title("AirPressure");
axe[2, 1].set_visible(False)
axe[2, 2].set_visible(False)
# Select numerical columns
numerical_data = df.select_dtypes(include=[np.number])

# Scatter plots to explore relationships between SystemProduction and other variables
target = 'SystemProduction'
features = numerical_data.columns.drop(target)

# Determine the number of rows and columns for subplots
num_features = len(features)
num_rows = (num_features // 3) + (1 if num_features % 3 != 0 else 0)  # Adjust rows based on features

# Create the subplots grid
fig, axes = plt.subplots(nrows=num_rows, ncols=3, figsize=(15, num_rows * 5))

# Flatten axes for easy iteration, in case of fewer subplots than grid size
axes = axes.flatten()

# Generate scatter plots
for i, feature in enumerate(features):
    sns.scatterplot(ax=axes[i], data=numerical_data, x=feature, y=target, alpha=0.6)
    axes[i].set_title(f'{target} vs {feature}', fontsize=10)

# Remove any unused subplots if number of features is less than available grid spaces
for j in range(i+1, len(axes)):
    fig.delaxes(axes[j])

fig.tight_layout(pad=2.0)
plt.show()

variables = ['WindSpeed', 'Sunshine', 'AirPressure', 'Radiation', 'AirTemperature', 'RelativeAirHumidity', 'SystemProduction']

for i,variable in enumerate(variables):
    plt.figure(figsize=(15, 10))
    plt.subplot(4,2,i+1)
    sns.lineplot(data=df[variable])
    plt.title(variable)
    plt.xlabel('Date')
    plt.ylabel(variable)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

sns.set()
plt.figure(figsize=(12, 4))
sns.lineplot(x= df.index, y = 'SystemProduction', data=df, color = 'red')
plt.title('Total power production')
plt.ylabel('Power Produced (MW)')
plt.xlabel('Date')
plt.show()
import pandas as pd
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\Lenovo\Desktop\Harsash\solar power\Solar Power Plant Data.csv')

# Convert 'Date' column to datetime and set it as the index
df.rename(columns={"Date-Hour(NMT)":"Date"}, inplace=True)  # Rename if necessary
df["Date"] = pd.to_datetime(df["Date"], format='%d.%m.%Y-%H:%M')  # Adjust format if necessary
df.set_index("Date", inplace=True)

# Resampling data to daily, weekly, and monthly averages
daily_production = df['SystemProduction'].resample('D').sum()
weekly_production = df['SystemProduction'].resample('W').sum()
monthly_production = df['SystemProduction'].resample('M').sum()

# Plotting the resampled data
plt.figure(figsize=(18, 12))

plt.subplot(3, 1, 1)
daily_production.plot(title='Daily Solar Power Production', color='orange')
plt.ylabel('Daily Production (kWh)')

plt.subplot(3, 1, 2)
weekly_production.plot(title='Weekly Solar Power Production', color='green')
plt.ylabel('Weekly Production (kWh)')

plt.subplot(3, 1, 3)
monthly_production.plot(title='Monthly Solar Power Production', color='blue')
plt.ylabel('Monthly Production (kWh)')

plt.tight_layout()
plt.show()

# Analyzing production by hour of the day
hourly_means = df['SystemProduction'].groupby(df.index.hour).mean()

# Plotting the average hourly production
plt.figure(figsize=(10, 6))
hourly_means.plot(kind='bar', color='purple')
plt.title('Average Hourly Solar Power Production')
plt.xlabel('Hour of the Day')
plt.ylabel('Average Production (kWh)')
plt.xticks(rotation=0)
plt.show()

# Plot radiation over time 
plt.figure(figsize=(12, 6))
df['Radiation'][:500].plot()  # Using a subset  to avoid clutter
plt.title('Radiation Over Time (First 500 Entries)')
plt.xlabel('Time Index')
plt.ylabel('Radiation')
plt.show()
# Binning temperature and radiation
df['TempBins'] = pd.cut(df['AirTemperature'], bins=5)
df['RadBins'] = pd.cut(df['Radiation'], bins=5)

# Calculate mean production for each combination of binned values
heatmap_data = df.groupby(['TempBins', 'RadBins'])['SystemProduction'].mean().unstack()

plt.figure(figsize=(10, 8))
sns.heatmap(heatmap_data, annot=True, cmap='YlOrRd', cbar_kws={'label': 'Mean System Production'})
plt.title('Mean System Production by Temperature and Radiation Levels')
plt.xlabel('Radiation Bins')
plt.ylabel('Temperature Bins')
plt.show()
#correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), cmap='coolwarm', annot=True, fmt=".1f")
plt.title('Correlation Matrix ', fontsize=24)
plt.show()
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Sample DataFrame creation (replace this with your actual DataFrame)
# df = pd.read_csv('your_data.csv', parse_dates=['your_date_column'], index_col='your_date_column')

# Example DataFrame
data = {
    'Date': ['2017-09-25', '2017-09-26', '2017-09-27', '2017-09-28', '2017-09-29', '2017-09-30', '2017-10-01'],
    'SystemProduction': [100, 150, 200, 250, 300, 350, 400]
}
df = pd.DataFrame(data)
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)

# Ensure the index is datetime
df.index = pd.to_datetime(df.index)

# Splitting the data into train and test sets
train = df.loc[df.index < '2017-09-30']
test = df.loc[df.index >= '2017-09-30']

# Plotting the Train-Test split
plt.figure(figsize=(16, 8))
sns.lineplot(x=train.index, y='SystemProduction', data=train, label='Train Set')
sns.lineplot(x=test.index, y='SystemProduction', data=test, label='Test Set')

plt.title('Train-Test Split', fontsize=24)
plt.ylabel('Power Produced (MW)', fontsize=14)
plt.xlabel('Date', fontsize=14)
plt.xticks(rotation=45) 
plt.legend()
plt.show()

# %% [markdown]
# # Data Preparation and Setup
# 
# In this cell we import the required libraries, generate a synthetic dataset,
# and prepare the data (train/test split and scaling).

# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from scipy.stats import uniform, randint
from sklearn.datasets import make_classification

import warnings
warnings.filterwarnings('ignore')

# Generate a synthetic classification dataset
X, y = make_classification(
    n_samples=1000,
    n_features=5,
    n_informative=5,
    n_redundant=0,
    n_clusters_per_class=1,
    flip_y=0.1,         # ~10% label noise
    class_sep=2.0,      # increased class separation for easier classification
    random_state=42
)

# Create a DataFrame
feature_cols = [f'feature_{i+1}' for i in range(X.shape[1])]
df = pd.DataFrame(X, columns=feature_cols)
df['target'] = y

# Split into features and target
X = df[feature_cols]
y = df['target']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Apply scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Dictionary to store model results
model_results = {}

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import randint


threshold = np.median(y_train)
y_train_disc = (y_train > threshold).astype(int)
y_test_disc = (y_test > threshold).astype(int)

# --- Define the RandomForestClassifier and its hyperparameter distribution ---
rf = RandomForestClassifier(random_state=42)
rf_params = {
    'n_estimators': randint(100, 500),
    'max_depth': randint(10, 50),
    'min_samples_split': randint(2, 10),
    'min_samples_leaf': randint(1, 5)
}

# --- Perform RandomizedSearchCV for the RandomForestClassifier ---
rf_search = RandomizedSearchCV(
    rf,
    param_distributions=rf_params,
    n_iter=20,
    cv=5,
    scoring='accuracy',
    random_state=42,
    n_jobs=-1
)
rf_search.fit(X_train_scaled, y_train_disc)

# --- Print best parameters and evaluate the model ---
print("RandomForestClassifier Best Parameters:")
print(rf_search.best_params_)

rf_best = rf_search.best_estimator_
y_pred_rf = rf_best.predict(X_test_scaled)
accuracy_rf = accuracy_score(y_test_disc, y_pred_rf)
print(f"\nRandomForestClassifier Accuracy: {accuracy_rf:.4f}")
print("\nClassification Report:")
print(classification_report(y_test_disc, y_pred_rf))

# --- Compute and visualize the confusion matrix ---
cm_rf = confusion_matrix(y_test_disc, y_pred_rf)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')
plt.title('RandomForestClassifier Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()


model_results['RandomForestClassifier'] = {'accuracy': accuracy_rf, 'model': rf_best}

def predict_production_classification(wind_speed, sunshine, air_pressure, radiation, air_temperature, model_pipeline, scaler):
    
    # Create a DataFrame with the input features
    input_data = pd.DataFrame([[wind_speed, sunshine, air_pressure, radiation, air_temperature]],
                              columns=production_features)
    
    # Scale the input data
    input_data_scaled = scaler.transform(input_data)
    
    # Predict the class (0: Medium, 1: High)
    prediction = model_pipeline.predict(input_data_scaled)[0]
    production_label = {0: 'Medium', 1: 'High'}
    
    return {
        'WindSpeed': wind_speed,
        'Sunshine': sunshine,
        'AirPressure': air_pressure,
        'Radiation': radiation,
        'AirTemperature': air_temperature,
        'predicted_production': production_label.get(prediction, "Unknown")
    }

# -----------------------------
# 4. Randomly Select a Row & Make a Prediction
# -----------------------------
# Select a random row (using random_state for reproducibility)
random_row = df.sample(n=1, random_state=42)

# Extract input feature values from the selected row
wind_speed_val = random_row['WindSpeed'].values[0]
sunshine_val = random_row['Sunshine'].values[0]
air_pressure_val = random_row['AirPressure'].values[0]
radiation_val = random_row['Radiation'].values[0]
air_temperature_val = random_row['AirTemperature'].values[0]

# Retrieve the trained model and scaler
example_prod_pipeline = model_results['RandomForestClassifier']['model']
example_scaler = model_results['RandomForestClassifier']['scaler']

# Get the prediction
prediction_dict = predict_production_classification(
    wind_speed=wind_speed_val,
    sunshine=sunshine_val,
    air_pressure=air_pressure_val,
    radiation=radiation_val,
    air_temperature=air_temperature_val,
    model_pipeline=example_prod_pipeline,
    scaler=example_scaler
)

# Save and display the prediction in a DataFrame
prediction_df = pd.DataFrame([prediction_dict])
print("\n--- Random Input Production Classification Prediction ---")
print(prediction_df)
# Machine Learning libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
from scipy.stats import randint

# Set a seed for reproducibility
np.random.seed(42)

# -----------------------------
# 1. Generate Synthetic Data
# -----------------------------
data = {
    'WindSpeed': np.random.randint(5, 25, 100),       # WindSpeed between 5 and 25
    'Sunshine': np.random.randint(1, 12, 100),        # Sunshine hours between 1 and 12
    'AirPressure': np.random.randint(950, 1050, 100), # AirPressure in hPa
    'Radiation': np.random.randint(100, 1000, 100),   # Radiation between 100 and 1000
    'AirTemperature': np.random.randint(15, 35, 100), # Temperature between 15 and 35 °C
    'SystemProduction': np.random.randint(200, 600, 100)  # Production between 200 and 600 units
}
df = pd.DataFrame(data)



def predict_production_classification(wind_speed, sunshine, air_pressure, radiation, air_temperature, model_pipeline, scaler):
   
    input_data = pd.DataFrame([[wind_speed, sunshine, air_pressure, radiation, air_temperature]],
                              columns=production_features)
    
    # Scale the input data
    input_data_scaled = scaler.transform(input_data)
    
    # Predict production class (0 or 1)
    prediction = model_pipeline.predict(input_data_scaled)[0]
    production_label = {0: 'Low Production', 1: 'High Production'}
    
    return {
        'WindSpeed': wind_speed,
        'Sunshine': sunshine,
        'AirPressure': air_pressure,
        'Radiation': radiation,
        'AirTemperature': air_temperature,
        'predicted_production': production_label.get(prediction, "Unknown")
    }

random_row = df.sample(n=1, random_state=42)

# Extract feature values from the selected row
wind_speed_val      = random_row['WindSpeed'].values[0]
sunshine_val        = random_row['Sunshine'].values[0]
air_pressure_val    = random_row['AirPressure'].values[0]
radiation_val       = random_row['Radiation'].values[0]
air_temperature_val = random_row['AirTemperature'].values[0]

# Retrieve the trained model and scaler from model_results
example_prod_pipeline = model_results['RandomForestClassifier']['model']
example_scaler = model_results['RandomForestClassifier']['scaler']

# Get the production classification prediction for the selected row
production_prediction_dict = predict_production_classification(
    wind_speed=wind_speed_val,
    sunshine=sunshine_val,
    air_pressure=air_pressure_val,
    radiation=radiation_val,
    air_temperature=air_temperature_val,
    model_pipeline=example_prod_pipeline,
    scaler=example_scaler
)

# Save and display the prediction in a DataFrame
production_prediction_df = pd.DataFrame([production_prediction_dict])
print( "Input Production Classification Prediction ")
print(production_prediction_df)

production_prediction_df.to_csv(r'C:\Users\Lenovo\Desktop\Harsash\solar power\Solar Power Plant Data.csv', index=False)

# %% [markdown]
# # SVC Evaluation with RandomizedSearchCV
# 
# In this cell we perform hyperparameter tuning for an SVC using RandomizedSearchCV,
# evaluate the best estimator on the test set, and visualize the confusion matrix.

# %%
# Define SVC and its hyperparameter distribution
svc = SVC(random_state=42)
svc_params = {
    'C': uniform(0.1, 10.0),
    'kernel': ['rbf', 'linear'],
    'gamma': uniform(0.001, 0.1)
}

# Perform RandomizedSearchCV for SVC
svc_search = RandomizedSearchCV(
    svc,
    param_distributions=svc_params,
    n_iter=20,
    cv=5,
    scoring='accuracy',
    random_state=42,
    n_jobs=-1
)
svc_search.fit(X_train_scaled, y_train)

# Best parameters and estimator
print("SVC Best Parameters:")
print(svc_search.best_params_)

# Evaluate on the test set
svc_best = svc_search.best_estimator_
y_pred_svc = svc_best.predict(X_test_scaled)
accuracy_svc = accuracy_score(y_test, y_pred_svc)
print(f"\nSVC Accuracy: {accuracy_svc:.4f}")
print("\nClassification Report for SVC:")
print(classification_report(y_test, y_pred_svc))
predictions = {}  
predictions['SVC'] = pd.DataFrame(svc_best.predict(X_test_scaled), columns=['Predicted Rating'])['Predicted Rating']
print("Predictions for SVC:")
print(predictions['SVC'])

# Confusion Matrix visualization
cm_svc = confusion_matrix(y_test, y_pred_svc)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_svc, annot=True, fmt='d', cmap='Blues')
plt.title('SVC Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Save results
model_results['SVC'] = {'accuracy': accuracy_svc, 'model': svc_best}


# Machine Learning libraries
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
from scipy.stats import uniform

# Set a seed for reproducibility during model training (but not for the random row selection)
np.random.seed(42)

# -----------------------------
# 1. Generate Synthetic Data
# -----------------------------
data = {
    'WindSpeed': np.random.randint(5, 25, 100),       # WindSpeed between 5 and 25
    'Sunshine': np.random.randint(1, 12, 100),        # Sunshine hours between 1 and 12
    'AirPressure': np.random.randint(950, 1050, 100), # AirPressure in hPa
    'Radiation': np.random.randint(100, 1000, 100),   # Radiation between 100 and 1000
    'AirTemperature': np.random.randint(15, 35, 100), # Temperature between 15 and 35 °C
    'SystemProduction': np.random.randint(200, 600, 100)  # Production between 200 and 600 units
}
df = pd.DataFrame(data)

def predict_production_classification_svc(wind_speed, sunshine, air_pressure, radiation, air_temperature, model_pipeline, scaler):
   
    # Create a DataFrame with the input features
    input_data = pd.DataFrame([[wind_speed, sunshine, air_pressure, radiation, air_temperature]],
                              columns=production_features)
    
    # Scale the input data
    input_data_scaled = scaler.transform(input_data)
    
    # Predict production class (0 or 1)
    prediction = model_pipeline.predict(input_data_scaled)[0]
    production_label = {0: 'Low Production', 1: 'High Production'}
    
    return {
        'WindSpeed': wind_speed,
        'Sunshine': sunshine,
        'AirPressure': air_pressure,
        'Radiation': radiation,
        'AirTemperature': air_temperature,
        'predicted_production': production_label.get(prediction, "Unknown")
    }

random_row = df.sample(n=1)

# Extract feature values from the selected row
wind_speed_val      = random_row['WindSpeed'].values[0]
sunshine_val        = random_row['Sunshine'].values[0]
air_pressure_val    = random_row['AirPressure'].values[0]
radiation_val       = random_row['Radiation'].values[0]
air_temperature_val = random_row['AirTemperature'].values[0]

# Get the production classification prediction for the selected row using SVC
svc_prediction_dict = predict_production_classification_svc(
    wind_speed=wind_speed_val,
    sunshine=sunshine_val,
    air_pressure=air_pressure_val,
    radiation=radiation_val,
    air_temperature=air_temperature_val,
    model_pipeline=svc_best,
    scaler=scaler
)

# Save and display the prediction in a DataFrame
svc_prediction_df = pd.DataFrame([svc_prediction_dict])
print("Input Production Classification Prediction (SVC) ---")
print(svc_prediction_df)

# Save the prediction DataFrame to the specified CSV file
svc_prediction_df.to_csv(r'C:\Users\Lenovo\Desktop\Harsash\solar power\Solar Power Plant Data.csv', index=False)

# %% [markdown]
# # LogisticRegression Evaluation with RandomizedSearchCV
# 
# Here we tune a LogisticRegression model with RandomizedSearchCV, then evaluate and visualize it.

# %%
# Define LogisticRegression and its hyperparameter distribution
lr = LogisticRegression(random_state=42, max_iter=1000)
lr_params = {
    'C': uniform(0.1, 10.0),
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear', 'saga']
}

# Perform RandomizedSearchCV for LogisticRegression
lr_search = RandomizedSearchCV(
    lr,
    param_distributions=lr_params,
    n_iter=20,
    cv=5,
    scoring='accuracy',
    random_state=42,
    n_jobs=-1
)
lr_search.fit(X_train_scaled, y_train)

# Best parameters and estimator
print("LogisticRegression Best Parameters:")
print(lr_search.best_params_)

# Evaluate on the test set
lr_best = lr_search.best_estimator_
y_pred_lr = lr_best.predict(X_test_scaled)
accuracy_lr = accuracy_score(y_test, y_pred_lr)
print(f"\nLogisticRegression Accuracy: {accuracy_lr:.4f}")
print("\nClassification Report for LogisticRegression:")
print(classification_report(y_test, y_pred_lr))

# Confusion Matrix visualization
cm_lr = confusion_matrix(y_test, y_pred_lr)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Oranges')
plt.title('LogisticRegression Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Save results
model_results['LogisticRegression'] = {'accuracy': accuracy_lr, 'model': lr_best}

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning libraries
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
from scipy.stats import uniform

# Set a seed for reproducibility in model training
np.random.seed(42)


data = {
    'WindSpeed': np.random.randint(5, 25, 100),        # WindSpeed between 5 and 25
    'Sunshine': np.random.randint(1, 12, 100),         # Sunshine hours between 1 and 12
    'AirPressure': np.random.randint(950, 1050, 100),   # AirPressure in hPa
    'Radiation': np.random.randint(100, 1000, 100),     # Radiation between 100 and 1000
    'AirTemperature': np.random.randint(15, 35, 100),   # Temperature between 15 and 35 °C
    'SystemProduction': np.random.randint(200, 600, 100)  # Production between 200 and 600 units
}
df = pd.DataFrame(data)


def predict_production_classification_lr(wind_speed, sunshine, air_pressure, radiation, air_temperature, model_pipeline, scaler):
    
    # Create a DataFrame with the input features
    input_data = pd.DataFrame([[wind_speed, sunshine, air_pressure, radiation, air_temperature]],
                              columns=production_features)
    
    # Scale the input data
    input_data_scaled = scaler.transform(input_data)
    
    # Predict production class (0 or 1)
    prediction = model_pipeline.predict(input_data_scaled)[0]
    production_label = {0: 'Low Production', 1: 'High Production'}
    
    return {
        'WindSpeed': wind_speed,
        'Sunshine': sunshine,
        'AirPressure': air_pressure,
        'Radiation': radiation,
        'AirTemperature': air_temperature,
        'predicted_production': production_label.get(prediction, "Unknown")
    }


high_prod_rows = df[df['SystemProduction'] > threshold]
if not high_prod_rows.empty:
    random_row = high_prod_rows.sample(n=1)
else:
    random_row = df.sample(n=1)

# Extract feature values from the selected row
wind_speed_val = random_row['WindSpeed'].values[0]
sunshine_val = random_row['Sunshine'].values[0]
air_pressure_val = random_row['AirPressure'].values[0]
radiation_val = random_row['Radiation'].values[0]
air_temperature_val = random_row['AirTemperature'].values[0]

# Get the production classification prediction using LogisticRegression
lr_prediction_dict = predict_production_classification_lr(
    wind_speed=wind_speed_val,
    sunshine=sunshine_val,
    air_pressure=air_pressure_val,
    radiation=radiation_val,
    air_temperature=air_temperature_val,
    model_pipeline=lr_best,
    scaler=scaler
)

lr_prediction_df = pd.DataFrame([lr_prediction_dict])
print("Input Production Classification Prediction (LogisticRegression) ---")
print(lr_prediction_df)

# Save the prediction DataFrame to the specified CSV file
lr_prediction_df.to_csv(r'C:\Users\Lenovo\Desktop\Harsash\solar power\Solar Power Plant Data.csv', index=False)

# %% [markdown]
# # DecisionTree Evaluation with GridSearchCV
# 
# In this cell we perform grid search tuning on a DecisionTreeClassifier, evaluate the best model,
# and plot its confusion matrix.

# %%
# Define DecisionTree and its hyperparameter grid
dt = DecisionTreeClassifier(random_state=42)
dt_params = {
    'max_depth': [5, 10, 15, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy']
}

# Perform GridSearchCV for DecisionTree
dt_search = GridSearchCV(
    dt,
    param_grid=dt_params,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)
dt_search.fit(X_train_scaled, y_train)

# Best parameters and estimator
print("DecisionTree Best Parameters:")
print(dt_search.best_params_)

# Evaluate on the test set
dt_best = dt_search.best_estimator_
y_pred_dt = dt_best.predict(X_test_scaled)
accuracy_dt = accuracy_score(y_test, y_pred_dt)
print(f"\nDecisionTree Accuracy: {accuracy_dt:.4f}")
print("\nClassification Report for DecisionTree:")
print(classification_report(y_test, y_pred_dt))

# Confusion Matrix visualization
cm_dt = confusion_matrix(y_test, y_pred_dt)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Purples')
plt.title('DecisionTree Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Save results
model_results['DecisionTree'] = {'accuracy': accuracy_dt, 'model': dt_best}

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning libraries
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler

# Set a seed for reproducibility in model training
np.random.seed(42)

data = {
    'WindSpeed': np.random.randint(5, 40, 100),       
    'Sunshine': np.random.randint(1, 15, 100),         
    'AirPressure': np.random.randint(950, 1250, 100),   
    'Radiation': np.random.randint(100, 1200, 100),     
    'AirTemperature': np.random.randint(15, 55, 100),   
    'SystemProduction': np.random.randint(200, 900, 100)  
}
df = pd.DataFrame(data)


def predict_production_classification_dt(wind_speed, sunshine, air_pressure, radiation, air_temperature, model_pipeline, scaler):
    
    input_data = pd.DataFrame([[wind_speed, sunshine, air_pressure, radiation, air_temperature]],
                              columns=production_features)
    input_data_scaled = scaler.transform(input_data)
    prediction = model_pipeline.predict(input_data_scaled)[0]
    production_label = {0: 'Low Production', 1: 'High Production'}
    
    return {
        'WindSpeed': wind_speed,
        'Sunshine': sunshine,
        'AirPressure': air_pressure,
        'Radiation': radiation,
        'AirTemperature': air_temperature,
        'predicted_production': production_label.get(prediction, "Unknown")
    }


high_prod_rows = df[df['SystemProduction'] > threshold]
if not high_prod_rows.empty:
    random_row = high_prod_rows.sample(n=1)
else:
    random_row = df.sample(n=1)

# Extract feature values from the selected row
wind_speed_val = random_row['WindSpeed'].values[0]
sunshine_val = random_row['Sunshine'].values[0]
air_pressure_val = random_row['AirPressure'].values[0]
radiation_val = random_row['Radiation'].values[0]
air_temperature_val = random_row['AirTemperature'].values[0]

# Get the production classification prediction using DecisionTreeClassifier
dt_prediction_dict = predict_production_classification_dt(
    wind_speed=wind_speed_val,
    sunshine=sunshine_val,
    air_pressure=air_pressure_val,
    radiation=radiation_val,
    air_temperature=air_temperature_val,
    model_pipeline=dt_best,
    scaler=scaler
)

dt_prediction_df = pd.DataFrame([dt_prediction_dict])
print(" Input Production Classification Prediction (DecisionTree) ---")
print(dt_prediction_df)

# Save the prediction DataFrame to the specified CSV file
dt_prediction_df.to_csv(r'C:\Users\Lenovo\Desktop\Harsash\solar power\Solar Power Plant Data.csv', index=False)

# %% [markdown]
# # Gaussian Naive Bayes Evaluation
# 
# Here we train and evaluate a Gaussian Naive Bayes classifier and visualize its performance.

# %%
# Train Gaussian Naive Bayes
gnb = GaussianNB()
gnb.fit(X_train_scaled, y_train)

# Evaluate on the test set
y_pred_gnb = gnb.predict(X_test_scaled)
accuracy_gnb = accuracy_score(y_test, y_pred_gnb)
print(f"GaussianNB Accuracy: {accuracy_gnb:.4f}")
print("\nClassification Report for GaussianNB:")
print(classification_report(y_test, y_pred_gnb))

# Confusion Matrix visualization
cm_gnb = confusion_matrix(y_test, y_pred_gnb)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_gnb, annot=True, fmt='d', cmap='Reds')
plt.title('GaussianNB Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Save results
model_results['GaussianNB'] = {'accuracy': accuracy_gnb, 'model': gnb}

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning libraries
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler

# Set a seed for reproducibility in model training
np.random.seed(42)


data = {
    'WindSpeed': np.random.randint(5, 25, 100),        # WindSpeed between 5 and 25
    'Sunshine': np.random.randint(1, 12, 100),         # Sunshine hours between 1 and 12
    'AirPressure': np.random.randint(950, 1050, 100),   # AirPressure in hPa
    'Radiation': np.random.randint(100, 1000, 100),     # Radiation between 100 and 1000
    'AirTemperature': np.random.randint(15, 35, 100),   # Temperature between 15 and 35 °C
    'SystemProduction': np.random.randint(200, 600, 100)  # Production between 200 and 600 units
}
df = pd.DataFrame(data)



def predict_production_classification_gnb(wind_speed, sunshine, air_pressure, radiation, air_temperature, model_pipeline, scaler):
    """
    Make a production classification prediction using the trained GaussianNB classifier.
    
    Parameters:
      - wind_speed, sunshine, air_pressure, radiation, air_temperature: Input feature values.
      - model_pipeline: The trained GaussianNB classifier.
      - scaler: The scaler used to transform the input features.
    
    Returns:
      A dictionary with the input features and the predicted production level.
      (0 maps to 'Low Production' and 1 maps to 'High Production').
    """
    # Create a DataFrame with the input features
    input_data = pd.DataFrame([[wind_speed, sunshine, air_pressure, radiation, air_temperature]],
                              columns=production_features)
    
    # Scale the input data
    input_data_scaled = scaler.transform(input_data)
    
    # Predict production class (0 or 1)
    prediction = model_pipeline.predict(input_data_scaled)[0]
    production_label = {0: 'Low Production', 1: 'High Production'}
    
    return {
        'WindSpeed': wind_speed,
        'Sunshine': sunshine,
        'AirPressure': air_pressure,
        'Radiation': radiation,
        'AirTemperature': air_temperature,
        'predicted_production': production_label.get(prediction, "Unknown")
    }

high_prod_rows = df[df['SystemProduction'] > threshold]
if not high_prod_rows.empty:
    random_row = high_prod_rows.sample(n=1)
else:
    random_row = df.sample(n=1)

# Extract feature values from the selected row
wind_speed_val      = random_row['WindSpeed'].values[0]
sunshine_val        = random_row['Sunshine'].values[0]
air_pressure_val    = random_row['AirPressure'].values[0]
radiation_val       = random_row['Radiation'].values[0]
air_temperature_val = random_row['AirTemperature'].values[0]

# Get the production classification prediction using GaussianNB
gnb_prediction_dict = predict_production_classification_gnb(
    wind_speed=wind_speed_val,
    sunshine=sunshine_val,
    air_pressure=air_pressure_val,
    radiation=radiation_val,
    air_temperature=air_temperature_val,
    model_pipeline=gnb,
    scaler=scaler
)

# Save and display the prediction in a DataFrame
gnb_prediction_df = pd.DataFrame([gnb_prediction_dict])
print(" Input Production Classification Prediction (GaussianNB) ---")
print(gnb_prediction_df)

# Save the prediction DataFrame to the specified CSV file
gnb_prediction_df.to_csv(r'C:\Users\Lenovo\Desktop\Harsash\solar power\Solar Power Plant Data.csv', index=False)

# %% [code]
import pandas as pd

svc_accuracy = 0.96
rf_accuracy = 0.90
lr_accuracy = 0.96
dt_accuracy = 0.95
gnb_accuracy = 0.945


results_data = {
    "Model": ["SVC", "RandomForest", "LogisticRegression", "DecisionTree", "GaussianNB"],
    "Accuracy": [svc_accuracy, rf_accuracy, lr_accuracy, dt_accuracy, gnb_accuracy],
}

results_df = pd.DataFrame(results_data)

# Visualize the accuracy using a bar chart
plt.figure(figsize=(10, 6))
sns.barplot(x="Model", y="Accuracy", data=results_df, palette="viridis")
plt.ylim(0, 1)  # accuracy ranges between 0 and 1
plt.title("Comparison of Model Accuracies")
plt.xlabel("Model")
plt.ylabel("Accuracy")
plt.show()
print("Combined Model Evaluation Metrics:")
display(results_df)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
from scipy.stats import randint


np.random.seed(42)  # For reproducibility
n_samples = 200

# Generate features
df = pd.DataFrame({
    'WindSpeed': np.random.randint(5, 25, n_samples),           # WindSpeed between 5 and 24
    'Sunshine': np.random.randint(1, 12, n_samples),              # Sunshine hours between 1 and 11
    'AirPressure': np.random.randint(950, 1050, n_samples),       # AirPressure in hPa
    'Radiation': np.random.randint(100, 1000, n_samples),         # Radiation between 100 and 999
    'AirTemperature': np.random.randint(15, 35, n_samples)        # Temperature between 15 and 34°C
})

# Define SystemProduction with a linear relationship plus noise
df['SystemProduction'] = (
    10 +
    3 * df['WindSpeed'] + 
    2 * df['Sunshine'] + 
    0.1 * df['AirPressure'] + 
    0.5 * df['Radiation'] + 
    1.5 * df['AirTemperature'] +
    np.random.normal(0, 25, n_samples)  # Noise with standard deviation 25
)


X = df[['WindSpeed', 'Sunshine', 'AirPressure', 'Radiation', 'AirTemperature']]
y = df['SystemProduction']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


rf_reg = RandomForestRegressor(random_state=42)
param_dist = {
    'n_estimators': randint(100, 500),
    'max_depth': randint(10, 50),
    'min_samples_split': randint(2, 10),
    'min_samples_leaf': randint(1, 5)
}

rf_search = RandomizedSearchCV(
    rf_reg,
    param_distributions=param_dist,
    n_iter=20,
    cv=5,
    scoring='r2',  # R² score for regression
    random_state=42,
    n_jobs=-1
)

rf_search.fit(X_train_scaled, y_train)
best_model = rf_search.best_estimator_


y_pred = best_model.predict(X_test_scaled)
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

print("RandomForestRegressor Best Parameters:")
print(rf_search.best_params_)
print(f"Test R² Score: {r2:.4f}")
print(f"Test MSE: {mse:.4f}")

# Visualization: True vs Predicted System Production
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("True System Production")
plt.ylabel("Predicted System Production")
plt.title("True vs Predicted System Production")
plt.show()

def predict_system_production(wind_speed, sunshine, air_pressure, radiation, air_temperature):
    """
    Predict the system production as a continuous number based on environmental parameters.
    
    Parameters:
        wind_speed (int or float): Wind speed value.
        sunshine (int or float): Hours of sunshine.
        air_pressure (int or float): Air pressure in hPa.
        radiation (int or float): Radiation value.
        air_temperature (int or float): Air temperature in °C.
        
    Returns:
        dict: A dictionary with the predicted system production.
    """
    # Create a DataFrame for the input sample
    input_data = pd.DataFrame([[wind_speed, sunshine, air_pressure, radiation, air_temperature]],
                              columns=['WindSpeed', 'Sunshine', 'AirPressure', 'Radiation', 'AirTemperature'])
    
    # Scale the input data
    input_data_scaled = scaler.transform(input_data)
    

    prediction = best_model.predict(input_data_scaled)[0]
    
    return {'predicted_system_production': round(prediction, 2)}

example_prediction = predict_system_production(10, 8, 980, 500, 25)
print("Example Prediction:")
print(example_prediction)
